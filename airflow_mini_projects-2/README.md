# Airflow Mini-Project #2

This mini-project will build on the work you did in your previous Airflow mini-project.
Once you have scheduled a DAG object in Airflow, you need to monitor the status of various
jobs in your pipeline on a regular basis. One way to monitor the job status is to analyze the log
messages generated from each run. In this project, you will create a log analyzer in Python to
monitor the DAG Airflow you set up in the previous mini-project.
Your log analyzer should show the following information:
- The total count of error messages
- A detailed message regarding each error
Learning Objectives
With this mini-project, you will exercise the text processing techniques using Python. Parsing
text files and getting useful information from logs is a common practice in real life projects. Also,
you will learn where the logs are located in Airflow processes.
In this mini-project, you will:
- Use text processing techniques in Python to make sense of logs
- Learn where logs are located in Airflow
- Learn how to monitor automated Airflow DAGs to ensure they are working properly

Final Output

![Screen Shot 2022-02-17 at 12 00 13 AM](https://user-images.githubusercontent.com/60493376/154431412-7e72181a-8b00-42e1-89b4-e57260bd6847.png)
